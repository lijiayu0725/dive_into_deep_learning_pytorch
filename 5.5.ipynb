{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "from torch import optim\n",
    "from torch.nn import init\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5),\n",
    "    nn.Sigmoid(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5),\n",
    "    nn.Sigmoid(),\n",
    "    nn.MaxPool2d(2),\n",
    "    d2l.FlattenLayer(),\n",
    "    nn.Linear(256, 120),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:\t torch.Size([1, 6, 24, 24])\n",
      "output shape:\t torch.Size([1, 6, 12, 12])\n",
      "output shape:\t torch.Size([1, 16, 8, 8])\n",
      "output shape:\t torch.Size([1, 16, 4, 4])\n",
      "output shape:\t torch.Size([1, 256])\n",
      "output shape:\t torch.Size([1, 120])\n",
      "output shape:\t torch.Size([1, 84])\n",
      "output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1, 1, 28, 28))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    if type(layer) is not nn.Sigmoid:\n",
    "        print('output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "epoch 1, loss 0.0091, train acc 0.101, test acc 0.100, time 1.5 sec\n",
      "epoch 2, loss 0.0069, train acc 0.324, test acc 0.510, time 1.4 sec\n",
      "epoch 3, loss 0.0036, train acc 0.641, test acc 0.673, time 1.4 sec\n",
      "epoch 4, loss 0.0028, train acc 0.714, test acc 0.718, time 1.4 sec\n",
      "epoch 5, loss 0.0025, train acc 0.747, test acc 0.721, time 1.4 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.9, 5\n",
    "net = net.to(device)\n",
    "for layer in net:\n",
    "    if type(layer) not in [nn.Sigmoid, nn.ReLU, nn.MaxPool2d, d2l.FlattenLayer]:\n",
    "        init.xavier_normal_(layer.weight)\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
